# ==============================================================================
# DeepTutor Environment Configuration
# ==============================================================================
# Copy this file to `.env` and fill in the values.
# Required fields are marked with [Required], optional fields with [Optional].

# ==============================================================================
# Server Ports
# ==============================================================================

# [Optional] Backend API server port
BACKEND_PORT=8001

# [Optional] Frontend server port
FRONTEND_PORT=3782

# ==============================================================================
# LLM Configuration (Large Language Model)
# ==============================================================================
# Primary LLM for all AI operations (chat, research, solve, etc.)

# [Required] Provider binding: openai, azure_openai, anthropic,
# deepseek, openrouter, groq, together, mistral
# ollama, lm_studio, vllm, llama_cpp
LLM_BINDING=openai

# [Required] Model name (e.g., gpt-4o, deepseek-chat, claude-3-5-sonnet)
LLM_MODEL=gpt-4o

# [Required] API key for the LLM provider
LLM_API_KEY=sk-xxx

# [Required] API endpoint URL
LLM_HOST=https://api.openai.com/v1

# [Optional] API version (required for Azure OpenAI)
LLM_API_VERSION=

# ==============================================================================
# Embedding Configuration
# ==============================================================================
# Embedding model for RAG (Retrieval-Augmented Generation)

# [Required] Provider: openai, azure_openai, jina,
# cohere, huggingface, google, ollama, lm_studio
EMBEDDING_BINDING=openai

# [Required] Model name
EMBEDDING_MODEL=text-embedding-3-small

# [Required] API key
EMBEDDING_API_KEY=sk-xxx

# [Required] API endpoint URL
EMBEDDING_HOST=https://api.openai.com/v1

# [Required] Vector dimensions (must match model output)
EMBEDDING_DIMENSION=3072

# [Optional] API version (for Azure OpenAI)
EMBEDDING_API_VERSION=

# ==============================================================================
# TTS Configuration (Text-to-Speech)
# ==============================================================================
# Optional: Enable audio narration features

# [Optional] Provider: openai, azure_openai
TTS_BINDING=openai

# [Optional] TTS model name
TTS_MODEL=tts-1

# [Optional] API key (can be same as LLM_API_KEY for OpenAI)
TTS_API_KEY=sk-xxx

# [Optional] API endpoint URL
TTS_URL=https://api.openai.com/v1

# [Optional] Voice: alloy, echo, fable, onyx, nova, shimmer
TTS_VOICE=alloy

# [Optional] API version (for Azure OpenAI)
TTS_BINDING_API_VERSION=

# ==============================================================================
# Search Configuration (Web Search)
# ==============================================================================
# Optional: Enable web search capabilities

# [Optional] Provider: perplexity, tavily, serper, jina, exa
SEARCH_PROVIDER=perplexity

# [Optional] API key for your chosen search provider
SEARCH_API_KEY=pplx-xxx

# ==============================================================================
# Cloud Deployment Configuration
# ==============================================================================
# Required when deploying to cloud/remote servers

# [Optional] External API base URL for cloud deployment
# Set this to your server's public URL when deploying remotely
# Example: https://your-server.com:8001 or https://api.yourdomain.com
NEXT_PUBLIC_API_BASE_EXTERNAL=

# [Optional] Direct API base URL (alternative to above)
NEXT_PUBLIC_API_BASE=

# ==============================================================================
# Debug & Development
# ==============================================================================

# [Optional] Disable SSL verification (not recommended for production)
DISABLE_SSL_VERIFY=false

# ==============================
# HuggingFace / MinerU (Optional)
# ==============================

# Use a HuggingFace mirror endpoint (optional)
# HF_ENDPOINT=https://your-hf-mirror.example.com

# HuggingFace cache directory (recommended: mount this in Docker to reuse cache)
# HF_HOME=/app/data/hf

# Force offline mode (requires models already downloaded into the cache)
# HF_HUB_OFFLINE=1
